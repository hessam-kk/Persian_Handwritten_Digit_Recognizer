{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset for google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run these cells at the first time of running project\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell when you upload the dataset in your colab\n",
    "!unzip -q \"/content/dataset.zip\" -d \"/content/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this cell whean you connect your drive and load dataset from drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!unzip -q \"/content/drive/MyDrive/Colab Notebooks/dataset.zip\" -d \"/content/drive/MyDrive/dataset/\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config dataset addresses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = \"/content/drive/MyDrive/dataset/csvTrainImages 60k x 784.csv\"\n",
    "label_train = \"/content/drive/MyDrive/dataset/csvTrainLabel 60k x 1.csv\"\n",
    "img_test = \"/content/drive/MyDrive/dataset/csvTestImages 10k x 784.csv\"\n",
    "label_test = \"/content/drive/MyDrive/dataset/csvTestLabel 10k x 1.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "images_train = np.loadtxt(open(img_train), delimiter=',')\n",
    "label_train = np.loadtxt(open(label_train), delimiter=',')\n",
    "images_test = np.loadtxt(open(img_test), delimiter=',')\n",
    "label_test = np.loadtxt(open(label_test), delimiter=',')\n",
    "\n",
    "# train images count is 60K (60K train image and 60K their labels)\n",
    "print(\"Size of data loaded for train images is: {}\".format(images_train.shape))\n",
    "print(\"Size of data loaded for train labels is: {}\".format(label_train.shape))\n",
    "# test image count is 10K (10K test image and 10K their labels)\n",
    "print(\"Size of data loaded for test images is: {}\".format(images_test.shape))\n",
    "print(\"Size of data loaded for test labels is: {}\".format(label_test.shape))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting the raw samples without any preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randint\n",
    "\n",
    "count_of_instances = 10 # set it to 6 to get the project appeal\n",
    "_, axes = plt.subplots(nrows=1, ncols=count_of_instances,\n",
    "                       figsize=(count_of_instances, 3))\n",
    "\n",
    "for ax in axes:\n",
    "    idx = randint(0, 60000) # choose a random element\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(images_train[idx].reshape(28, 28).T,\n",
    "              cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Value: %i\" % label_train[idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "for item in range(images_train.shape[0]):\n",
    "  images_train[item] = cv2.normalize(images_train[item], \n",
    "                                     None, 0, 1.0, \n",
    "                                     cv2.NORM_MINMAX, dtype=cv2.CV_32F).reshape((28*28,))\n",
    "\n",
    "for item in range(images_test.shape[0]):\n",
    "  images_test[item] = cv2.normalize(images_test[item], \n",
    "                                    None, 0, 1.0, \n",
    "                                    cv2.NORM_MINMAX, dtype=cv2.CV_32F).reshape((28*28,))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# train\n",
    "for item in range(images_train.shape[0]):\n",
    "  images_train[item] = cv2.threshold(images_train[item],\n",
    "                                     0.2, 1.0, cv2.THRESH_BINARY)[1].reshape((28*28,))\n",
    "  \n",
    "# test\n",
    "for item in range(images_test.shape[0]):\n",
    "  images_test[item] = cv2.threshold(images_test[item], \n",
    "                                    0.2, 1.0, cv2.THRESH_BINARY)[1].reshape((28*28,))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erosion & Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Erosion on 0s and Dilation to all numbers to fix the\n",
    "## broken vector caused by very large 0s and making the learning better.\n",
    "\n",
    "import cv2\n",
    "kernel = np.array([[0,1,1,1,0],\n",
    "                   [0,1,1,1,0],\n",
    "                   [1,1,1,1,1],\n",
    "                   [0,1,1,1,0],\n",
    "                   [0,1,1,1,0]], dtype=np.uint8)\n",
    "# train\n",
    "for item in range(images_train.shape[0]):\n",
    "  if label_train[item] == 0:\n",
    "    images_train[item] = cv2.erode(images_train[item].reshape((28,28)),\n",
    "                                   kernel).reshape((784,))\n",
    "    images_train[item] = cv2.erode(images_train[item].reshape((28,28)), \n",
    "                                   kernel).reshape((784,))\n",
    "\n",
    "  images_train[item] = cv2.dilate(images_train[item].reshape((28,28)), \n",
    "                                  np.ones((3,3), np.uint8)  ).reshape((784,))\n",
    "  images_train[item] = cv2.erode(images_train[item].reshape((28,28)), \n",
    "                                 np.ones((3,3), np.uint8)).reshape((784,))\n",
    "\n",
    "\n",
    "# test\n",
    "for item in range(images_test.shape[0]):\n",
    "  if label_test[item] == 0:\n",
    "    images_test[item] = cv2.erode(images_test[item].reshape((28,28)), \n",
    "                                  kernel).reshape((784,))\n",
    "    images_test[item] = cv2.erode(images_test[item].reshape((28,28)), \n",
    "                                  kernel).reshape((784,))\n",
    "\n",
    "  images_test[item] = cv2.dilate(images_test[item].reshape((28,28)), \n",
    "                                 np.ones((3,3), np.uint8)  ).reshape((784,))\n",
    "  images_test[item] = cv2.erode(images_test[item].reshape((28,28)), \n",
    "                                np.ones((3,3), np.uint8)).reshape((784,))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closing (Not Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this action may cause the accuracy to be lower than when it had not been applied\n",
    "## you can skip running this cell\n",
    "\n",
    "## Train\n",
    "import cv2\n",
    "kernel = np.array([[1,1,1,1],\n",
    "                   [1,1,1,1],\n",
    "                   [1,1,1,1],\n",
    "                   [1,1,1,1],\n",
    "                   ], dtype=np.uint8)\n",
    "\n",
    "for item in range(images_train.shape[0]):\n",
    "  images_train[item] = cv2.morphologyEx(images_train[item].reshape((28,28)), \n",
    "                                        cv2.MORPH_CLOSE, kernel).reshape((28*28,))\n",
    "\n",
    "## test\n",
    "for item in range(images_test.shape[0]):\n",
    "    images_train[item] = cv2.morphologyEx(images_train[item].reshape((28,28)), \n",
    "                                          cv2.MORPH_CLOSE, kernel).reshape((28*28,))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting Samples after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randint\n",
    "\n",
    "count_of_instances = 10 \n",
    "_, axes = plt.subplots(nrows=1, ncols=count_of_instances,\n",
    "                       figsize=(count_of_instances, 3))\n",
    "\n",
    "for ax in axes:\n",
    "    idx = randint(0, 60000) # choose a random element\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(images_train[idx].reshape(28, 28).T,\n",
    "              cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Value: %i\" % label_train[idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model Using Various Parameters & Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16/relu -> 16/relu -> 10/softmax | optimizer=SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(28*28,)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='sgd', \n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(images_train, label_train, \n",
    "          epochs=10, batch_size=16, \n",
    "          validation_data=(images_test, label_test))\n",
    "\n",
    "## FIT RESULT ##\n",
    "## with raw dataset\n",
    "#### loss: 1.8946 - accuracy: 0.1926 - val_loss: 1.9064 - val_accuracy: 0.1922\n",
    "## with Erosion\n",
    "#### loss: 1.6763 - accuracy: 0.2852 - val_loss: 1.6968 - val_accuracy: 0.2873\n",
    "## with Erosion then Closing\n",
    "#### loss: 1.9716 - accuracy: 0.2649 - val_loss: 1.9856 - val_accuracy: 0.2598\n",
    "## with Thresholding then Erosion then Closing\n",
    "## loss: 1.8743 - accuracy: 0.1994 - val_loss: 1.8705 - val_accuracy: 0.1933\n",
    "## Nomal then Thresholding then Erosion then Closing\n",
    "#### loss: 0.0459 - accuracy: 0.9872 - val_loss: 0.0695 - val_accuracy: 0.9792\n",
    "## Nomal then Thresholding then Dilate+Erosion \n",
    "#### loss: 0.0566 - accuracy: 0.9844 - val_loss: 0.0930 - val_accuracy: 0.9740\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate \n",
    "test_loss, test_accuracy = model.evaluate(images_test, label_test)\n",
    "print(test_loss, test_accuracy)\n",
    "\n",
    "## Evaluate RESULT\n",
    "## Raw Dataset\n",
    "#### loss: 0.1289 - accuracy: 0.9698 \n",
    "## Erosion\n",
    "#### loss: 0.1012 - accuracy: 0.9761\n",
    "## Erosion then Closing\n",
    "#### loss: 0.1359 - accuracy: 0.9727\n",
    "## Ersoion then dilation \n",
    "#### loss: 0.1137 - accuracy: 0.9773\n",
    "## Thresholding ==> Erosion ==> Closing\n",
    "#### loss: 1.8705 - accuracy: 0.1933\n",
    "## Nomal ==> Thresholding ==> Erosion ==> Closing\n",
    "#### loss: 0.0652 - accuracy: 0.9847\n",
    "## Nomal ==> Thresholding ==> Dilate+Erosion \n",
    "#### loss: 0.0710 - accuracy: 0.9839"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
