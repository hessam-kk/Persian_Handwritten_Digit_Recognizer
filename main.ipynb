{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset for google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run these cells at the first time of running project\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell when you upload the dataset in your colab\n",
    "!unzip -q \"/content/dataset.zip\" -d \"/content/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this cell whean you connect your drive and load dataset from drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!unzip -q \"/content/drive/MyDrive/Colab Notebooks/dataset.zip\" -d \"/content/drive/MyDrive/dataset/\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config dataset addresses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = \"/content/drive/MyDrive/dataset/csvTrainImages 60k x 784.csv\"\n",
    "label_train = \"/content/drive/MyDrive/dataset/csvTrainLabel 60k x 1.csv\"\n",
    "img_test = \"/content/drive/MyDrive/dataset/csvTestImages 10k x 784.csv\"\n",
    "label_test = \"/content/drive/MyDrive/dataset/csvTestLabel 10k x 1.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "images_train = np.loadtxt(open(img_train), delimiter=',')\n",
    "label_train = np.loadtxt(open(label_train), delimiter=',')\n",
    "images_test = np.loadtxt(open(img_test), delimiter=',')\n",
    "label_test = np.loadtxt(open(label_test), delimiter=',')\n",
    "\n",
    "# train images count is 60K (60K train image and 60K their labels)\n",
    "print(\"Size of data loaded for train images is: {}\".format(images_train.shape))\n",
    "print(\"Size of data loaded for train labels is: {}\".format(label_train.shape))\n",
    "# test image count is 10K (10K test image and 10K their labels)\n",
    "print(\"Size of data loaded for test images is: {}\".format(images_test.shape))\n",
    "print(\"Size of data loaded for test labels is: {}\".format(label_test.shape))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting the raw samples without any preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randint\n",
    "\n",
    "count_of_instances = 10 # set it to 6 to get the project appeal\n",
    "_, axes = plt.subplots(nrows=1, ncols=count_of_instances,\n",
    "                       figsize=(count_of_instances, 3))\n",
    "\n",
    "for ax in axes:\n",
    "    idx = randint(0, 60000) # choose a random element\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(images_train[idx].reshape(28, 28).T,\n",
    "              cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Value: %i\" % label_train[idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "for item in range(images_train.shape[0]):\n",
    "  images_train[item] = cv2.normalize(images_train[item], \n",
    "                                     None, 0, 1.0, \n",
    "                                     cv2.NORM_MINMAX, dtype=cv2.CV_32F).reshape((28*28,))\n",
    "\n",
    "for item in range(images_test.shape[0]):\n",
    "  images_test[item] = cv2.normalize(images_test[item], \n",
    "                                    None, 0, 1.0, \n",
    "                                    cv2.NORM_MINMAX, dtype=cv2.CV_32F).reshape((28*28,))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# train\n",
    "for item in range(images_train.shape[0]):\n",
    "  images_train[item] = cv2.threshold(images_train[item],\n",
    "                                     0.2, 1.0, cv2.THRESH_BINARY)[1].reshape((28*28,))\n",
    "  \n",
    "# test\n",
    "for item in range(images_test.shape[0]):\n",
    "  images_test[item] = cv2.threshold(images_test[item], \n",
    "                                    0.2, 1.0, cv2.THRESH_BINARY)[1].reshape((28*28,))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erosion & Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Erosion on 0s and Dilation to all numbers to fix the\n",
    "## broken vector caused by very large 0s and making the learning better.\n",
    "\n",
    "import cv2\n",
    "kernel = np.array([[0,1,1,1,0],\n",
    "                   [0,1,1,1,0],\n",
    "                   [1,1,1,1,1],\n",
    "                   [0,1,1,1,0],\n",
    "                   [0,1,1,1,0]], dtype=np.uint8)\n",
    "# train\n",
    "for item in range(images_train.shape[0]):\n",
    "  if label_train[item] == 0:\n",
    "    images_train[item] = cv2.erode(images_train[item].reshape((28,28)),\n",
    "                                   kernel).reshape((784,))\n",
    "    images_train[item] = cv2.erode(images_train[item].reshape((28,28)), \n",
    "                                   kernel).reshape((784,))\n",
    "\n",
    "  images_train[item] = cv2.dilate(images_train[item].reshape((28,28)), \n",
    "                                  np.ones((3,3), np.uint8)  ).reshape((784,))\n",
    "  images_train[item] = cv2.erode(images_train[item].reshape((28,28)), \n",
    "                                 np.ones((3,3), np.uint8)).reshape((784,))\n",
    "\n",
    "\n",
    "# test\n",
    "for item in range(images_test.shape[0]):\n",
    "  if label_test[item] == 0:\n",
    "    images_test[item] = cv2.erode(images_test[item].reshape((28,28)), \n",
    "                                  kernel).reshape((784,))\n",
    "    images_test[item] = cv2.erode(images_test[item].reshape((28,28)), \n",
    "                                  kernel).reshape((784,))\n",
    "\n",
    "  images_test[item] = cv2.dilate(images_test[item].reshape((28,28)), \n",
    "                                 np.ones((3,3), np.uint8)  ).reshape((784,))\n",
    "  images_test[item] = cv2.erode(images_test[item].reshape((28,28)), \n",
    "                                np.ones((3,3), np.uint8)).reshape((784,))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closing (Not Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this action may cause the accuracy to be lower than when it had not been applied\n",
    "## you can skip running this cell\n",
    "\n",
    "## Train\n",
    "import cv2\n",
    "kernel = np.array([[1,1,1,1],\n",
    "                   [1,1,1,1],\n",
    "                   [1,1,1,1],\n",
    "                   [1,1,1,1],\n",
    "                   ], dtype=np.uint8)\n",
    "\n",
    "for item in range(images_train.shape[0]):\n",
    "  images_train[item] = cv2.morphologyEx(images_train[item].reshape((28,28)), \n",
    "                                        cv2.MORPH_CLOSE, kernel).reshape((28*28,))\n",
    "\n",
    "## test\n",
    "for item in range(images_test.shape[0]):\n",
    "    images_train[item] = cv2.morphologyEx(images_train[item].reshape((28,28)), \n",
    "                                          cv2.MORPH_CLOSE, kernel).reshape((28*28,))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting Samples after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randint\n",
    "\n",
    "count_of_instances = 10 \n",
    "_, axes = plt.subplots(nrows=1, ncols=count_of_instances,\n",
    "                       figsize=(count_of_instances, 3))\n",
    "\n",
    "for ax in axes:\n",
    "    idx = randint(0, 60000) # choose a random element\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(images_train[idx].reshape(28, 28).T,\n",
    "              cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Value: %i\" % label_train[idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model Using Various Parameters & Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16/relu -> 16/relu -> 10/softmax | optimizer=SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(28*28,)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='sgd', \n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(images_train, label_train, \n",
    "          epochs=10, batch_size=16, \n",
    "          validation_data=(images_test, label_test))\n",
    "\n",
    "## FIT RESULT ##\n",
    "## with raw dataset\n",
    "#### loss: 1.8946 - accuracy: 0.1926 - val_loss: 1.9064 - val_accuracy: 0.1922\n",
    "## with Erosion\n",
    "#### loss: 1.6763 - accuracy: 0.2852 - val_loss: 1.6968 - val_accuracy: 0.2873\n",
    "## with Erosion then Closing\n",
    "#### loss: 1.9716 - accuracy: 0.2649 - val_loss: 1.9856 - val_accuracy: 0.2598\n",
    "## with Thresholding then Erosion then Closing\n",
    "## loss: 1.8743 - accuracy: 0.1994 - val_loss: 1.8705 - val_accuracy: 0.1933\n",
    "## Nomal then Thresholding then Erosion then Closing\n",
    "#### loss: 0.0459 - accuracy: 0.9872 - val_loss: 0.0695 - val_accuracy: 0.9792\n",
    "## Nomal then Thresholding then Dilate+Erosion \n",
    "#### loss: 0.0566 - accuracy: 0.9844 - val_loss: 0.0930 - val_accuracy: 0.9740\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate \n",
    "test_loss, test_accuracy = model.evaluate(images_test, label_test)\n",
    "print(test_loss, test_accuracy)\n",
    "\n",
    "## Evaluate RESULT\n",
    "## Raw Dataset\n",
    "#### loss: 2.3026 - accuracy: 0.1000\n",
    "## Erosion\n",
    "#### loss: 1.6968 - accuracy: 0.2873\n",
    "## Erosion ==> Closing\n",
    "#### loss: 1.9856 - accuracy: 0.2598\n",
    "## Thresholding ==> Erosion ==> Closing\n",
    "#### loss: 1.8705 - accuracy: 0.1933\n",
    "## Nomal ==> Thresholding ==> Erosion ==> Closing\n",
    "#### loss: 0.0695 - accuracy: 0.9792\n",
    "## Nomal ==> Thresholding ==> Dilate+Erosion \n",
    "#### loss: 0.0930 - accuracy: 0.9740"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32/relu -> 32/relu -> 32/relu -> 10/softmax | Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(28*28,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(images_train, label_train,\n",
    "          epochs=8, batch_size=32,\n",
    "          validation_data=(images_test, label_test))\n",
    "\n",
    "## FIT RESULT ##\n",
    "## raw dataset\n",
    "#### loss: 0.0538 - accuracy: 0.9851 - val_loss: 0.1289 - val_accuracy: 0.9698\n",
    "## Erosion\n",
    "#### loss: 0.0458 - accuracy: 0.9880 - val_loss: 0.1012 - val_accuracy: 0.9761\n",
    "## Erosion ==> Closing (kernel: 9*1)\n",
    "#### loss: 0.0536 - accuracy: 0.9865 - val_loss: 0.1359 - val_accuracy: 0.9727\n",
    "## Ersoion ==> dilation \n",
    "#### loss: 0.0447 - accuracy: 0.9888 - val_loss: 0.1137 - val_accuracy: 0.9773\n",
    "## Thresholding ==> Erosion ==> Closing\n",
    "#### loss: 0.0533 - accuracy: 0.9860 - val_loss: 0.1338 - val_accuracy: 0.9731\n",
    "## Nomal ==> Thresholding ==> Erosion ==> Closing\n",
    "#### loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0652 - val_accuracy: 0.9847\n",
    "## Nomal ==> Thresholding ==> Dilate+Erosion \n",
    "#### loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.0710 - val_accuracy: 0.9839"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate \n",
    "test_loss, test_accuracy = model.evaluate(images_test, label_test)\n",
    "print(test_loss, test_accuracy)\n",
    "\n",
    "## Evaluate RESULT\n",
    "## Raw Dataset\n",
    "#### loss: 0.1289 - accuracy: 0.9698 \n",
    "## Erosion\n",
    "#### loss: 0.1012 - accuracy: 0.9761\n",
    "## Erosion then Closing\n",
    "#### loss: 0.1359 - accuracy: 0.9727\n",
    "## Ersoion then dilation \n",
    "#### loss: 0.1137 - accuracy: 0.9773\n",
    "## Thresholding ==> Erosion ==> Closing\n",
    "#### loss: 1.8705 - accuracy: 0.1933\n",
    "## Nomal ==> Thresholding ==> Erosion ==> Closing\n",
    "#### loss: 0.0652 - accuracy: 0.9847\n",
    "## Nomal ==> Thresholding ==> Dilate+Erosion \n",
    "#### loss: 0.0710 - accuracy: 0.9839"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third model (best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "512/relu, 64/relu -> 10/softmax | Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCURACY_THRESHOLD = 0.988\n",
    "# ACCURACY_THRESHOLD = 0.995\n",
    "class myCallback(keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('val_accuracy') > ACCURACY_THRESHOLD):   \n",
    "          print(\"\\nReached %2.2f%% accuracy, so stopping training!!\"\\\n",
    "                %(ACCURACY_THRESHOLD*100))   \n",
    "          self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape=(28*28, ), activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(images_train, label_train, \n",
    "          epochs=10, batch_size=256, \n",
    "          validation_data=(images_test, label_test), \n",
    "          callbacks=[callbacks])\n",
    "\n",
    "\n",
    "## FIT RESULT ##\n",
    "## raw dataset\n",
    "#### loss: 0.2492 - accuracy: 0.9392 - val_loss: 0.3228 - val_accuracy: 0.9265\n",
    "## Erosion 3.22\n",
    "#### loss: 0.0860 - accuracy: 0.9808 - val_loss: 0.1561 - val_accuracy: 0.9702\n",
    "## Erosion ==> Closing\n",
    "#### loss: 0.0854 - accuracy: 0.9816 - val_loss: 0.1923 - val_accuracy: 0.9636\n",
    "## Thresholding ==> Erosion ==> Closing\n",
    "####loss: 0.0878 - accuracy: 0.9784 - val_loss: 0.1747 - val_accuracy: 0.9669\n",
    "## Thresholding ==> Erosion ==> Closing (32Neurons)\n",
    "#### loss: 0.0795 - accuracy: 0.9859 - val_loss: 0.2930 - val_accuracy: 0.9750\n",
    "## Nomal ==> Thresholding ==> Erosion ==> Closing\n",
    "#### loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.0886 - val_accuracy: 0.9820\n",
    "## Nomal ==> Thresholding ==> Dilate+Erosion \n",
    "#### loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0999 - val_accuracy: 0.9811\n",
    "## 3 Layer\n",
    "#### loss: 6.0452e-04 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9880"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate third model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate \n",
    "test_loss, test_accuracy = model.evaluate(images_test, label_test)\n",
    "print(test_loss, test_accuracy)\n",
    "\n",
    "## Evaluate RESULT\n",
    "## Raw Dataset\n",
    "#### loss: 0.3228 - accuracy: 0.9265 \n",
    "## Erosion\n",
    "#### loss: 0.1561 - accuracy: 0.9702\n",
    "## Erosion then Closing\n",
    "#### loss: 0.1923 - accuracy: 0.9636\n",
    "## Thresholding ==> Erosion ==> Closing\n",
    "#### loss: 0.1747 - accuracy: 0.9669\n",
    "## Thresholding ==> Erosion ==> Closing (32Neurons)\n",
    "#### loss: 0.2930 - accuracy: 0.9750\n",
    "## Nomal ==> Thresholding ==> Erosion ==> Closing\n",
    "#### loss: 0.0886 - accuracy: 0.9820\n",
    "## Nomal ==> Thresholding ==> Dilate+Erosion \n",
    "## 3 Layer\n",
    "#### loss: 0.0779 - accuracy: 0.9845"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing images with their actual label & prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "\n",
    "predictions = model.predict(images_test)\n",
    "\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "count_of_instances = 10 \n",
    "_, axes = plt.subplots(nrows=1, ncols=count_of_instances, \n",
    "                       figsize=(count_of_instances, 3))\n",
    "\n",
    "wrong_pred = np.where(predicted_labels != label_test)[0]\n",
    "print(len(wrong_pred))\n",
    "\n",
    "for ax in axes:\n",
    "    idx = wrong_pred[randint(0, 120)] \n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(images_test[idx].reshape(28, 28).T, \n",
    "              cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"{}-> [{}]\".format(int(label_train[idx]), \n",
    "                                    predicted_labels[idx]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
